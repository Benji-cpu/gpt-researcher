{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config class definition\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Config class for GPT Researcher.\"\"\"\n",
    "\n",
    "    def __init__(self, config_file: str = None):\n",
    "        \"\"\"Initialize the config class.\"\"\"\n",
    "        self.config_file = config_file if config_file else os.getenv('CONFIG_FILE')\n",
    "        self.retriever = os.getenv('SEARCH_RETRIEVER', \"tavily\")\n",
    "        self.embedding_provider = os.getenv('EMBEDDING_PROVIDER', 'openai')\n",
    "        self.llm_provider = os.getenv('LLM_PROVIDER', \"openai\")\n",
    "        self.fast_llm_model = os.getenv('FAST_LLM_MODEL', \"gpt-3.5-turbo\")\n",
    "        self.smart_llm_model = os.getenv('SMART_LLM_MODEL', \"gpt-4o\")\n",
    "        self.fast_token_limit = int(os.getenv('FAST_TOKEN_LIMIT', 2000))\n",
    "        self.smart_token_limit = int(os.getenv('SMART_TOKEN_LIMIT', 4000))\n",
    "        self.browse_chunk_max_length = int(os.getenv('BROWSE_CHUNK_MAX_LENGTH', 8192))\n",
    "        self.summary_token_limit = int(os.getenv('SUMMARY_TOKEN_LIMIT', 700))\n",
    "        self.temperature = float(os.getenv('TEMPERATURE', 0.55))\n",
    "        self.user_agent = os.getenv('USER_AGENT', \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                                                 \"(KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 Edg/119.0.0.0\")\n",
    "        self.max_search_results_per_query = int(os.getenv('MAX_SEARCH_RESULTS_PER_QUERY', 5))\n",
    "        self.memory_backend = os.getenv('MEMORY_BACKEND', \"local\")\n",
    "        self.total_words = int(os.getenv('TOTAL_WORDS', 1000))\n",
    "        self.report_format = os.getenv('REPORT_FORMAT', \"APA\")\n",
    "        self.max_iterations = int(os.getenv('MAX_ITERATIONS', 3))\n",
    "        self.agent_role = os.getenv('AGENT_ROLE', None)\n",
    "        self.scraper = os.getenv(\"SCRAPER\", \"bs\")\n",
    "        self.max_subtopics = os.getenv(\"MAX_SUBTOPICS\", 3)\n",
    "        self.load_config_file()\n",
    "\n",
    "    def load_config_file(self) -> None:\n",
    "        \"\"\"Load the config file.\"\"\"\n",
    "        if self.config_file is None:\n",
    "            return None\n",
    "        with open(self.config_file, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "        for key, value in config.items():\n",
    "            self.__dict__[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Config object\n",
    "config = Config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sf_researcher.utils.llm import *\n",
    "from sf_researcher.utils.validators import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy data for testing\n",
    "\n",
    "test_task = \"Research the company's directors and generate a report.\"\n",
    "test_data = \"Sample data related to the company and its directors.\"\n",
    "test_sub_query = \"Find information about the director John Doe.\"\n",
    "test_visited_urls = [\"http://example.com/director1\", \"http://example.com/director2\"]\n",
    "test_company = \"Example Company Inc.\"\n",
    "test_context = \"Sample context for the company report.\"\n",
    "test_config = {\n",
    "    \"smart_llm_model\": \"gpt-3.5-turbo\",\n",
    "    \"fast_llm_model\": \"gpt-3.5-turbo\",\n",
    "    \"llm_provider\": \"openai\",\n",
    "    \"max_subtopics\": 5\n",
    "}\n",
    "\n",
    "# Create a dummy compliance report request\n",
    "compliance_report_request = {\n",
    "    \"query\": \"Investigate the compliance status of Example Company Inc.\",\n",
    "    \"salesforce_id\": \"001xx000003DGbOAAW\",\n",
    "    \"directors\": [\"John Doe\", \"Jane Smith\"],\n",
    "    \"include_domains\": [\"example.com\"],\n",
    "    \"exclude_domains\": [\"exclude-example.com\"],\n",
    "    \"parent_sub_queries\": [\"Parent query example\"],\n",
    "    \"child_sub_queries\": [\"Child query example\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test functions\n",
    "\n",
    "def test_get_provider():\n",
    "    try:\n",
    "        provider = get_provider(\"openai\")\n",
    "        print(f\"Provider: {provider}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_create_chat_completion():\n",
    "    try:\n",
    "        response = await create_chat_completion(\n",
    "            messages=[{\"role\": \"user\", \"content\": test_task}],\n",
    "            model=test_config[\"smart_llm_model\"],\n",
    "            temperature=0.7,\n",
    "            llm_provider=test_config[\"llm_provider\"]\n",
    "        )\n",
    "        print(f\"Chat Completion Response: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
