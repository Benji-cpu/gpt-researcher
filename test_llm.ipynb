{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config class definition\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Config class for GPT Researcher.\"\"\"\n",
    "\n",
    "    def __init__(self, config_file: str = None):\n",
    "        \"\"\"Initialize the config class.\"\"\"\n",
    "        self.config_file = config_file if config_file else os.getenv('CONFIG_FILE')\n",
    "        self.retriever = os.getenv('SEARCH_RETRIEVER', \"tavily\")\n",
    "        self.embedding_provider = os.getenv('EMBEDDING_PROVIDER', 'openai')\n",
    "        self.llm_provider = os.getenv('LLM_PROVIDER', \"openai\")\n",
    "        self.fast_llm_model = os.getenv('FAST_LLM_MODEL', \"gpt-3.5-turbo\")\n",
    "        self.smart_llm_model = os.getenv('SMART_LLM_MODEL', \"gpt-4o\")\n",
    "        self.fast_token_limit = int(os.getenv('FAST_TOKEN_LIMIT', 2000))\n",
    "        self.smart_token_limit = int(os.getenv('SMART_TOKEN_LIMIT', 4000))\n",
    "        self.browse_chunk_max_length = int(os.getenv('BROWSE_CHUNK_MAX_LENGTH', 8192))\n",
    "        self.summary_token_limit = int(os.getenv('SUMMARY_TOKEN_LIMIT', 700))\n",
    "        self.temperature = float(os.getenv('TEMPERATURE', 0.55))\n",
    "        self.user_agent = os.getenv('USER_AGENT', \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                                                 \"(KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 Edg/119.0.0.0\")\n",
    "        self.max_search_results_per_query = int(os.getenv('MAX_SEARCH_RESULTS_PER_QUERY', 5))\n",
    "        self.memory_backend = os.getenv('MEMORY_BACKEND', \"local\")\n",
    "        self.total_words = int(os.getenv('TOTAL_WORDS', 1000))\n",
    "        self.report_format = os.getenv('REPORT_FORMAT', \"APA\")\n",
    "        self.max_iterations = int(os.getenv('MAX_ITERATIONS', 3))\n",
    "        self.agent_role = os.getenv('AGENT_ROLE', None)\n",
    "        self.scraper = os.getenv(\"SCRAPER\", \"bs\")\n",
    "        self.max_subtopics = os.getenv(\"MAX_SUBTOPICS\", 3)\n",
    "        self.load_config_file()\n",
    "\n",
    "    def load_config_file(self) -> None:\n",
    "        \"\"\"Load the config file.\"\"\"\n",
    "        if self.config_file is None:\n",
    "            return None\n",
    "        with open(self.config_file, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "        for key, value in config.items():\n",
    "            self.__dict__[key] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Config object\n",
    "config = Config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import asyncio\n",
    "from sf_researcher.utils.llm import *\n",
    "from sf_researcher.utils.validators import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy data for testing\n",
    "\n",
    "test_task = \"Research the company's directors and generate a report.\"\n",
    "test_data = \"Example Company Inc. is a multinational corporation specializing in technology and software solutions.\"\n",
    "test_sub_query = \"Find information about the director John Doe.\"\n",
    "test_visited_urls = [\"http://example.com/director1\", \"http://example.com/director2\"]\n",
    "test_company = \"Example Company Inc.\"\n",
    "test_context = \"Contextual information about Example Company Inc. for detailed research.\"\n",
    "test_config = {\n",
    "    \"smart_llm_model\": \"gpt-3.5-turbo\",\n",
    "    \"fast_llm_model\": \"gpt-3.5-turbo\",\n",
    "    \"llm_provider\": \"openai\",\n",
    "    \"max_subtopics\": 5\n",
    "}\n",
    "\n",
    "# Create a dummy compliance report request\n",
    "compliance_report_request = {\n",
    "    \"query\": \"Investigate the compliance status of Example Company Inc.\",\n",
    "    \"salesforce_id\": \"001xx000003DGbOAAW\",\n",
    "    \"directors\": [\"John Doe\", \"Jane Smith\"],\n",
    "    \"include_domains\": [\"example.com\"],\n",
    "    \"exclude_domains\": [\"exclude-example.com\"],\n",
    "    \"parent_sub_queries\": [\"Parent query example\"],\n",
    "    \"child_sub_queries\": [\"Child query example\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test functions\n",
    "\n",
    "def test_get_provider():\n",
    "    try:\n",
    "        provider = get_provider(\"openai\")\n",
    "        print(f\"Provider: {provider}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Completion Response: To generate a report on a company's directors, you can start by researching the company's official website, as well as other reliable sources such as business databases, news articles, and press releases. Look for information on each director's background, experience, qualifications, and any other relevant details that may be of interest.\n",
      "\n",
      "Once you have gathered all the necessary information, you can compile a report that includes the following details for each director:\n",
      "\n",
      "1. Name: Provide the full name of the director.\n",
      "2. Position: Specify the role or position held by the director within the company.\n",
      "3. Background: Include a summary of the director's professional background, education, and any relevant experience.\n",
      "4. Achievements: Highlight any notable achievements or contributions made by the director in their career.\n",
      "5. Board memberships: List any other boards or organizations on which the director serves.\n",
      "6. Skills and expertise: Identify the key skills and expertise that the director brings to the company.\n",
      "7. Relationships: Note any relationships or connections that the director may have with other key individuals or organizations.\n",
      "8. Compensation: If available, provide information on the director's compensation package.\n",
      "9. Governance: Evaluate the director's role in the company's governance structure and any committees they may serve on.\n",
      "10. Potential conflicts of interest: Identify any potential conflicts of interest that the director may have due to their other roles or affiliations.\n",
      "\n",
      "By compiling this information into a comprehensive report, you can gain a better understanding of the company's leadership team and the individuals responsible for guiding its strategic direction and decision-making processes.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def test_create_chat_completion():\n",
    "    try:\n",
    "        response = await create_chat_completion(\n",
    "            messages=[{\"role\": \"user\", \"content\": test_task}],\n",
    "            model=test_config[\"smart_llm_model\"],\n",
    "            temperature=0.7,\n",
    "            llm_provider=test_config[\"llm_provider\"]\n",
    "        )\n",
    "        print(f\"Chat Completion Response: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# To run the async function\n",
    "await test_create_chat_completion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Completion Response: As an AI language model, I don't have access to real-time data or the ability to browse the internet to generate a report on a specific company's directors. However, you can easily find information about a company's directors by visiting the company's official website, checking their annual reports, or looking up their profile on professional networking sites like LinkedIn.\n",
      "\n",
      "Typically, a report on a company's directors would include information such as their names, professional backgrounds, areas of expertise, roles within the company, and any other relevant details about their qualifications and experience. This information can provide valuable insights into the leadership team of the company and help stakeholders understand the individuals responsible for guiding the company's strategic direction and decision-making.\n"
     ]
    }
   ],
   "source": [
    "async def test_create_chat_completion():\n",
    "    try:\n",
    "        response = await create_chat_completion(\n",
    "            messages=[{\"role\": \"user\", \"content\": test_task}],\n",
    "            model=test_config[\"smart_llm_model\"],\n",
    "            temperature=0.7,\n",
    "            llm_provider=test_config[\"llm_provider\"]\n",
    "        )\n",
    "        print(f\"Chat Completion Response: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# To run the async function\n",
    "asyncio.run(test_create_chat_completion())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
